# -*- coding: utf-8 -*-
import os, json
from pathlib import Path
from typing import List, Dict, Tuple
import numpy as np, faiss
from sentence_transformers import SentenceTransformer
from ingest.chunkers import semantic_chunk
from ingest.loaders import load_docs_from_dir

INDEX_DIR = Path(os.getenv("INDEX_DIR", "./data/index"))
RAW_DIR = Path("./data/raw")
EMB_MODEL_NAME = os.getenv("EMBEDDING_MODEL", "sentence-transformers/all-MiniLM-L6-v2")

def build_index(docs: List[Dict], emb) -> Tuple[faiss.Index, List[Dict]]:
    """
    æ–‡æ¡£ â†’ åˆ†å— â†’ å‘é‡åŒ–ï¼ˆå½’ä¸€åŒ–ï¼‰â†’ ç»„è£… FAISS Index + å…ƒæ•°æ®
    """
    vectors, metas = [], []
    total_chunks = 0

    print(f"ğŸ“‚ åŠ è½½åˆ° {len(docs)} ç¯‡æ–‡æ¡£ï¼Œå¼€å§‹åˆ†å—å’Œå‘é‡åŒ–...")

    for doc_id, d in enumerate(docs, 1):
        chunks = semantic_chunk(d["content"])
        print(f"  â†’ æ–‡æ¡£ {doc_id}/{len(docs)}: {d['path']} åˆ†æˆ {len(chunks)} ä¸ªå—")

        for i, ck in enumerate(chunks):
            v = emb.encode(ck, normalize_embeddings=True)
            vectors.append(v)
            metas.append({"path": d["path"], "chunk_id": i, "text": ck})
            total_chunks += 1

            # æ¯ 100 ä¸ªå—æ‰“å°ä¸€æ¬¡
            if total_chunks % 100 == 0:
                print(f"    å·²å¤„ç† {total_chunks} ä¸ªåˆ†å—...")

    if not vectors:
        raise SystemExit("âš ï¸ æ²¡æœ‰å¯ä¾›ç´¢å¼•çš„æ–‡æœ¬å—ï¼Œè¯·æ£€æŸ¥ data/raw/ ä¸‹æ˜¯å¦æœ‰å†…å®¹ã€‚")

    X = np.vstack(vectors).astype("float32")
    index = faiss.IndexFlatIP(X.shape[1])  # å½’ä¸€åŒ–åç‚¹ç§¯â‰ˆä½™å¼¦
    index.add(X)

    print(f"âœ… å…¨éƒ¨åˆ†å—å®Œæˆï¼Œæ€»è®¡ {total_chunks} ä¸ªï¼Œå‘é‡ç»´åº¦ {X.shape[1]}")
    return index, metas

def save_index(index: faiss.Index, metas: List[Dict], out_dir: Path):
    out_dir.mkdir(parents=True, exist_ok=True)
    faiss.write_index(index, str(out_dir / "faiss.index"))
    with open(out_dir / "meta.jsonl", "w", encoding="utf-8") as f:
        for m in metas:
            f.write(json.dumps(m, ensure_ascii=False) + "\n")
    print(f"ğŸ’¾ ç´¢å¼•å·²ä¿å­˜åˆ° {out_dir} (faiss.index + meta.jsonl)")

def main():
    print(f"ğŸš€ ä½¿ç”¨ Embedding æ¨¡å‹: {EMB_MODEL_NAME}")
    emb = SentenceTransformer(EMB_MODEL_NAME, device="cuda")  # å¯ä»¥åŠ  device="cuda"
    docs = load_docs_from_dir(RAW_DIR)
    index, metas = build_index(docs, emb)
    save_index(index, metas, INDEX_DIR)

if __name__ == "__main__":
    main()
